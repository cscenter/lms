---
# Note: See `group_vars/all.yml` for variables shared between playbooks

- name: provision EC2 instance
  hosts: localhost
  connection: local
  gather_facts: False
  vars:
    # Remove if no backup volumes was created before (we are launching purely
    # new instance or manually removed all backup volumes for prev version)
    aws_ec2_prev_host_tag: "cscweb_new"
    aws_ec2_host: tag_Name_{{ aws_ec2_instance_tag }}
    aws_ec2_region: eu-central-1
    aws_ec2_instance_type: t3.medium
    aws_ec2_instance_volume_size: 16
    aws_ec2_keypair: csc
    # Ubuntu 16.04 hvm ssd
    aws_ec2_image: ami-0565af6e282977273
    aws_ec2_cpu_credit_specification: standard
    aws_ec2_root_device_name: /dev/sda1
    attach_second_volume: yes
    second_volume_size: 30
    # The device names that you specify in a block device mapping are renamed
    # using NVMe device names (/dev/nvme[0-26]n1). The block device driver
    # can assign NVMe device names in a different order than you specified
    # for the volumes in the block device mapping.
    # The device name is available through the NVMe controller vendor-specific extension
    # $ sudo apt-get install nvme-cli && sudo nvme id-ctrl -v /dev/nvme1n1
    second_volume_device_name: "/dev/xvdf"
    security_groups:
      - name: ssh
        desc: the security group for ssh-available server
        rules:
          - proto: tcp
            from_port: 22
            to_port: 22
            cidr_ip: 0.0.0.0/0
        rules_egress:
          - proto: all
            cidr_ip: 0.0.0.0/0
      - name: web
        desc: the security group for the web server
        rules:
          - proto: tcp
            from_port: 80
            to_port: 80
            cidr_ip: 0.0.0.0/0
          - proto: tcp
            from_port: 443
            to_port: 443
            cidr_ip: 0.0.0.0/0
        rules_egress:
          - proto: all
            cidr_ip: 0.0.0.0/0

  tasks:
    - name: Gather facts about any instance with tag "{{ aws_ec2_instance_tag }}"
      ec2_instance_facts:
        filters:
          "tag:Name": "{{ aws_ec2_instance_tag }}"
      register: ec2_instances_lookup

    - name: Check ec2 instance already exists
      fail:
        msg: "EC2 instance with tag.Name '{{ aws_ec2_instance_tag }}' already exists"
      when: ec2_instances_lookup["instances"]|length > 0

    - name: Create required network security groups
      ec2_group:
        name: "{{ item.name }}"
        description: "{{ item.desc }}"
        rules: "{{ item.rules }}"
        rules_egress: "{{ item.rules_egress }}"
        region: "{{ aws_ec2_region }}"
      with_items: "{{ security_groups }}"

    - name: Launch instance
      ec2_instance:
        name: "{{ aws_ec2_instance_tag }}"
        region: "{{ aws_ec2_region }}"
        key_name: "{{ aws_ec2_keypair }}"
        instance_type: "{{ aws_ec2_instance_type }}"
        image_id: "{{ aws_ec2_image_id }}"
        cpu_credit_specification: "{{ aws_ec2_cpu_credit_specification }}"
        termination_protection: yes
        security_groups:
          - web
          - ssh
        volumes:
          - device_name: "{{ aws_ec2_root_device_name }}"
            ebs:
              volume_size: "{{ aws_ec2_instance_volume_size }}"
              delete_on_termination: true
        wait: true
      register: ec2

    - name: display info for newly created instance
      debug:
        msg: "{{ ec2 }}"

    - name: Ensure root volume for launched instances is tagged
      ec2_tag:
        region: "{{ aws_ec2_region }}"
        # Note: Make sure to use the save device name as in `ec2` task
        resource: '{{ item.1.ebs.volume_id }}'
        state: present
        tags:
          Name: "{{ aws_ec2_instance_tag }}"
      loop: "{{ ec2.instances | subelements('block_device_mappings') }}"

    - name: display an IP of newly launched instance
      debug:
        msg: "{{ ec2.instances[0].public_ip_address }}"
      when: ec2.instances|length > 0

    - name: display an id of newly launched instance
      debug:
        msg: "{{ ec2.instances[0].instance_id }}"
      when: ec2.instances|length > 0

    - name: wait for SSH to become available
      local_action:
        wait_for host="{{ ec2.instances[0].public_ip_address }}" port=22 timeout=600
      when: ec2.instances|length > 0

    - name: add launched instances to host group
      local_action: add_host hostname={{ item.public_ip_address }} groupname={{ aws_ec2_host }}
      loop: "{{ ec2.instances }}"

    - name: Get info about all related backup snapshots
      ec2_snapshot_facts:
        region: "{{ aws_ec2_region }}"
        filters:
          "tag:Name": "{{ aws_ec2_prev_host_tag }}"
          status: completed
      register: snapshots_data
      when: aws_ec2_prev_host_tag is defined and attach_second_volume
      tags:
        - snapshot

    - name: Find the newest backup snapshot
      set_fact: newest_snapshot={{ snapshots_data.snapshots | sort(attribute='start_time') | last }}
      when: aws_ec2_prev_host_tag is defined and attach_second_volume and snapshots_data.snapshots | length > 0
      tags:
        - snapshot

    - set_fact: snapshot_id={{ newest_snapshot.snapshot_id }}
      when: newest_snapshot is defined and newest_snapshot.snapshot_id
      tags:
        - snapshot

    - name: Create volume and attach it to the EC2 instance
      ec2_vol:
        region: "{{ aws_ec2_region }}"
        snapshot: "{{ snapshot_id|default(omit) }}"
        instance: "{{ ec2.tagged_instances[0].instance_id }}"
        volume_size: "{{ second_volume_size }}"
        volume_type: gp2
        device_name: "{{ second_volume_device_name }}"
        tags:
          Name: "{{ aws_ec2_instance_tag }}"
          # TODO: Sync `EBSBackup` name (and value) with create_snapshot.py.jinja2
          EBSBackup: "Yes"
      register: ec2_vol
      when: attach_second_volume
      tags:
        - additional-volume

    # FIXME: move to the separated playbook
    - name: EBS volumes backup automation
      import_role:
        name: backup_ebs
      tags:
        - backup-automation
